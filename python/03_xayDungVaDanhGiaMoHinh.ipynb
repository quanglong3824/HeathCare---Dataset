{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NOTEBOOK 03: X√ÇY D·ª∞NG V√Ä ƒê√ÅNH GI√Å C√ÅC M√î H√åNH MACHINE LEARNING\n",
    "\n",
    "## M·ª•c ti√™u:\n",
    "- Chu·∫©n b·ªã d·ªØ li·ªáu cho machine learning\n",
    "- X√¢y d·ª±ng v√† so s√°nh nhi·ªÅu m√¥ h√¨nh kh√°c nhau\n",
    "- X·ª≠ l√Ω v·∫•n ƒë·ªÅ m·∫•t c√¢n b·∫±ng d·ªØ li·ªáu\n",
    "- ƒê√°nh gi√° hi·ªáu su·∫•t v√† l·ª±a ch·ªçn m√¥ h√¨nh t·ªët nh·∫•t\n",
    "- Ph√¢n t√≠ch feature importance v√† interpretability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. IMPORT TH∆Ø VI·ªÜN V√Ä T·∫¢I D·ªÆ LI·ªÜU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import c√°c th∆∞ vi·ªán c·∫ßn thi·∫øt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "# Metrics and Evaluation\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,\n",
    "    confusion_matrix, classification_report, roc_curve, precision_recall_curve\n",
    ")\n",
    "\n",
    "# Imbalanced Learning\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "\n",
    "# Feature Selection\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFE\n",
    "\n",
    "# Model Interpretation\n",
    "import shap\n",
    "\n",
    "# C·∫•u h√¨nh\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"‚úÖ ƒê√£ import th√†nh c√¥ng c√°c th∆∞ vi·ªán machine learning!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫£i d·ªØ li·ªáu\n",
    "try:\n",
    "    duLieu = pd.read_csv('../data_processed/du_lieu_da_xu_ly.csv')\n",
    "    print(\"‚úÖ ƒê√£ t·∫£i d·ªØ li·ªáu t·ª´ file ƒë√£ x·ª≠ l√Ω\")\nexcept:\n",
    "    # N·∫øu ch∆∞a c√≥ file x·ª≠ l√Ω, t·∫£i t·ª´ file g·ªëc\n",
    "    duLieu = pd.read_csv('../healthcare-dataset-stroke-data.csv.xls')\n",
    "    \n",
    "    # X·ª≠ l√Ω nhanh d·ªØ li·ªáu\n",
    "    duLieu['bmi'] = duLieu['bmi'].replace('N/A', np.nan)\n",
    "    duLieu['bmi'] = pd.to_numeric(duLieu['bmi'], errors='coerce')\n",
    "    duLieu['bmi'].fillna(duLieu['bmi'].median(), inplace=True)\n",
    "    \n",
    "    # T·∫°o c√°c feature m·ªõi\n",
    "    def phanLoaiTuoi(tuoi):\n",
    "        if tuoi < 18: return 'Tr·∫ª em'\n",
    "        elif tuoi < 30: return 'Tu·ªïi tr·∫ª'\n",
    "        elif tuoi < 50: return 'Trung ni√™n'\n",
    "        elif tuoi < 65: return 'Tr∆∞·ªõc h∆∞u'\n",
    "        else: return 'Tu·ªïi cao'\n",
    "    \n",
    "    def phanLoaiBMI(bmi):\n",
    "        if bmi < 18.5: return 'Thi·∫øu c√¢n'\n",
    "        elif bmi < 25: return 'B√¨nh th∆∞·ªùng'\n",
    "        elif bmi < 30: return 'Th·ª´a c√¢n'\n",
    "        else: return 'B√©o ph√¨'\n",
    "    \n",
    "    def phanLoaiGlucose(glucose):\n",
    "        if glucose < 100: return 'B√¨nh th∆∞·ªùng'\n",
    "        elif glucose < 126: return 'Ti·ªÅn ti·ªÉu ƒë∆∞·ªùng'\n",
    "        else: return 'Ti·ªÉu ƒë∆∞·ªùng'\n",
    "    \n",
    "    duLieu['nhomTuoi'] = duLieu['age'].apply(phanLoaiTuoi)\n",
    "    duLieu['nhomBMI'] = duLieu['bmi'].apply(phanLoaiBMI)\n",
    "    duLieu['nhomGlucose'] = duLieu['avg_glucose_level'].apply(phanLoaiGlucose)\n",
    "    \n",
    "    # T·∫°o ƒëi·ªÉm nguy c∆°\n",
    "    duLieu['diemNguyCo'] = (\n",
    "        duLieu['hypertension'] + \n",
    "        duLieu['heart_disease'] + \n",
    "        (duLieu['age'] > 65).astype(int) +\n",
    "        (duLieu['bmi'] > 30).astype(int) +\n",
    "        (duLieu['avg_glucose_level'] > 126).astype(int)\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ ƒê√£ t·∫£i v√† x·ª≠ l√Ω d·ªØ li·ªáu t·ª´ file g·ªëc\")\n",
    "\n",
    "print(f\"üìä K√≠ch th∆∞·ªõc d·ªØ li·ªáu: {duLieu.shape}\")\n",
    "print(f\"üéØ Ph√¢n ph·ªëi target: \\n{duLieu['stroke'].value_counts()}\")\n",
    "print(f\"üìã T·ª∑ l·ªá m·∫•t c√¢n b·∫±ng: {duLieu['stroke'].value_counts()[0]/duLieu['stroke'].value_counts()[1]:.1f}:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CHU·∫®N B·ªä D·ªÆ LI·ªÜU CHO MACHINE LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chu·∫©n b·ªã features v√† target\n",
    "print(\"üîß CHU·∫®N B·ªä D·ªÆ LI·ªÜU CHO MACHINE LEARNING:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Lo·∫°i b·ªè c·ªôt id v√† c√°c c·ªôt kh√¥ng c·∫ßn thi·∫øt\n",
    "cacCotLoaiBo = ['id']\n",
    "if 'id' in duLieu.columns:\n",
    "    duLieu = duLieu.drop(columns=cacCotLoaiBo)\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a features v√† target\n",
    "target = 'stroke'\n",
    "y = duLieu[target]\n",
    "X = duLieu.drop(columns=[target])\n",
    "\n",
    "print(f\"üìä S·ªë l∆∞·ª£ng features: {X.shape[1]}\")\n",
    "print(f\"üìä S·ªë l∆∞·ª£ng samples: {X.shape[0]}\")\n",
    "print(f\"üéØ Target distribution: {y.value_counts().to_dict()}\")\n",
    "\n",
    "# Ph√¢n lo·∫°i c√°c lo·∫°i bi·∫øn\n",
    "cacBienSo = ['age', 'avg_glucose_level', 'bmi', 'diemNguyCo']\n",
    "cacBienPhanLoai = ['gender', 'ever_married', 'work_type', 'Residence_type', 'smoking_status', \n",
    "                   'nhomTuoi', 'nhomBMI', 'nhomGlucose']\n",
    "cacBienBinary = ['hypertension', 'heart_disease']\n",
    "\n",
    "# Ki·ªÉm tra c√°c c·ªôt c√≥ t·ªìn t·∫°i kh√¥ng\n",
    "cacBienSo = [col for col in cacBienSo if col in X.columns]\n",
    "cacBienPhanLoai = [col for col in cacBienPhanLoai if col in X.columns]\n",
    "cacBienBinary = [col for col in cacBienBinary if col in X.columns]\n",
    "\n",
    "print(f\"\\nüìà Bi·∫øn s·ªë ({len(cacBienSo)}): {cacBienSo}\")\n",
    "print(f\"üìä Bi·∫øn ph√¢n lo·∫°i ({len(cacBienPhanLoai)}): {cacBienPhanLoai}\")\n",
    "print(f\"üî¢ Bi·∫øn binary ({len(cacBienBinary)}): {cacBienBinary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o preprocessing pipeline\n",
    "print(\"\\nüîÑ T·∫†O PREPROCESSING PIPELINE:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Pipeline cho bi·∫øn s·ªë\n",
    "pipelineBienSo = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline cho bi·∫øn ph√¢n lo·∫°i\n",
    "pipelineBienPhanLoai = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('onehot', OneHotEncoder(drop='first', sparse_output=False, handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Pipeline cho bi·∫øn binary\n",
    "pipelineBienBinary = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "# K·∫øt h·ª£p t·∫•t c·∫£ preprocessing\n",
    "boXuLyDuLieu = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', pipelineBienSo, cacBienSo),\n",
    "        ('cat', pipelineBienPhanLoai, cacBienPhanLoai),\n",
    "        ('bin', pipelineBienBinary, cacBienBinary)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "print(\"‚úÖ ƒê√£ t·∫°o preprocessing pipeline\")\n",
    "print(f\"   ‚Ä¢ Bi·∫øn s·ªë: Impute median + StandardScaler\")\n",
    "print(f\"   ‚Ä¢ Bi·∫øn ph√¢n lo·∫°i: Impute 'missing' + OneHotEncoder\")\n",
    "print(f\"   ‚Ä¢ Bi·∫øn binary: Impute most_frequent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chia d·ªØ li·ªáu train/test\n",
    "print(\"\\n‚úÇÔ∏è  CHIA D·ªÆ LI·ªÜU TRAIN/TEST:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"üìä Training set: {X_train.shape[0]} samples\")\n",
    "print(f\"üìä Test set: {X_test.shape[0]} samples\")\n",
    "print(f\"üéØ Train target distribution: {y_train.value_counts().to_dict()}\")\n",
    "print(f\"üéØ Test target distribution: {y_test.value_counts().to_dict()}\")\n",
    "\n",
    "# √Åp d·ª•ng preprocessing\n",
    "X_train_processed = boXuLyDuLieu.fit_transform(X_train)\n",
    "X_test_processed = boXuLyDuLieu.transform(X_test)\n",
    "\n",
    "print(f\"\\nüîß Sau preprocessing:\")\n",
    "print(f\"   ‚Ä¢ Training features shape: {X_train_processed.shape}\")\n",
    "print(f\"   ‚Ä¢ Test features shape: {X_test_processed.shape}\")\n",
    "\n",
    "# L·∫•y t√™n features sau preprocessing\n",
    "tenFeaturesSauXuLy = []\n",
    "\n",
    "# Features s·ªë\n",
    "tenFeaturesSauXuLy.extend(cacBienSo)\n",
    "\n",
    "# Features t·ª´ OneHot encoding\n",
    "if cacBienPhanLoai:\n",
    "    onehotEncoder = boXuLyDuLieu.named_transformers_['cat'].named_steps['onehot']\n",
    "    tenFeaturesPhanLoai = onehotEncoder.get_feature_names_out(cacBienPhanLoai)\n",
    "    tenFeaturesSauXuLy.extend(tenFeaturesPhanLoai)\n",
    "\n",
    "# Features binary\n",
    "tenFeaturesSauXuLy.extend(cacBienBinary)\n",
    "\n",
    "print(f\"   ‚Ä¢ T·ªïng s·ªë features sau x·ª≠ l√Ω: {len(tenFeaturesSauXuLy)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. X·ª¨ L√ù M·∫§T C√ÇN B·∫∞NG D·ªÆ LI·ªÜU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# So s√°nh c√°c ph∆∞∆°ng ph√°p x·ª≠ l√Ω m·∫•t c√¢n b·∫±ng\n",
    "print(\"‚öñÔ∏è  X·ª¨ L√ù M·∫§T C√ÇN B·∫∞NG D·ªÆ LI·ªÜU:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# T·∫°o c√°c ph∆∞∆°ng ph√°p sampling kh√°c nhau\n",
    "cacPhuongPhapSampling = {\n",
    "    'Original': None,\n",
    "    'RandomOverSampler': RandomOverSampler(random_state=42),\n",
    "    'SMOTE': SMOTE(random_state=42),\n",
    "    'SMOTETomek': SMOTETomek(random_state=42),\n",
    "    'RandomUnderSampler': RandomUnderSampler(random_state=42)\n",
    "}\n",
    "\n",
    "# L∆∞u tr·ªØ d·ªØ li·ªáu ƒë√£ sampling\n",
    "duLieuSampled = {}\n",
    "\n",
    "for tenPhuongPhap, phuongPhap in cacPhuongPhapSampling.items():\n",
    "    if phuongPhap is None:\n",
    "        X_sampled = X_train_processed\n",
    "        y_sampled = y_train\n",
    "    else:\n",
    "        X_sampled, y_sampled = phuongPhap.fit_resample(X_train_processed, y_train)\n",
    "    \n",
    "    duLieuSampled[tenPhuongPhap] = (X_sampled, y_sampled)\n",
    "    \n",
    "    phanPhoiTarget = pd.Series(y_sampled).value_counts().sort_index()\n",
    "    tyLe = phanPhoiTarget[1] / phanPhoiTarget[0] if phanPhoiTarget[0] > 0 else 0\n",
    "    \n",
    "    print(f\"\\nüìä {tenPhuongPhap}:\")\n",
    "    print(f\"   ‚Ä¢ T·ªïng samples: {len(y_sampled):,}\")\n",
    "    print(f\"   ‚Ä¢ Class 0: {phanPhoiTarget[0]:,}\")\n",
    "    print(f\"   ‚Ä¢ Class 1: {phanPhoiTarget[1]:,}\")\n",
    "    print(f\"   ‚Ä¢ T·ª∑ l·ªá (1:0): {tyLe:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bi·ªÉu ƒë·ªì so s√°nh c√°c ph∆∞∆°ng ph√°p sampling\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "fig.suptitle('So s√°nh c√°c ph∆∞∆°ng ph√°p x·ª≠ l√Ω m·∫•t c√¢n b·∫±ng d·ªØ li·ªáu', fontsize=16, fontweight='bold')\n",
    "\n",
    "axes = axes.flatten()\n",
    "mauSac = ['#2E8B57', '#DC143C']\n",
    "nhanNhom = ['Kh√¥ng ƒë·ªôt qu·ªµ (0)', 'C√≥ ƒë·ªôt qu·ªµ (1)']\n",
    "\n",
    "for i, (tenPhuongPhap, (X_sampled, y_sampled)) in enumerate(duLieuSampled.items()):\n",
    "    if i < len(axes):\n",
    "        phanPhoiTarget = pd.Series(y_sampled).value_counts().sort_index()\n",
    "        \n",
    "        bars = axes[i].bar(range(len(phanPhoiTarget)), phanPhoiTarget.values, \n",
    "                          color=mauSac, alpha=0.8)\n",
    "        \n",
    "        axes[i].set_title(f'{tenPhuongPhap}\\n({len(y_sampled):,} samples)', fontweight='bold')\n",
    "        axes[i].set_xticks(range(len(phanPhoiTarget)))\n",
    "        axes[i].set_xticklabels(nhanNhom, rotation=45, ha='right')\n",
    "        axes[i].set_ylabel('S·ªë l∆∞·ª£ng')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Th√™m nh√£n tr√™n c·ªôt\n",
    "        for bar, value in zip(bars, phanPhoiTarget.values):\n",
    "            axes[i].text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(phanPhoiTarget.values)*0.01, \n",
    "                        f'{value:,}', ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "\n",
    "# ·∫®n subplot th·ª´a\n",
    "if len(duLieuSampled) < len(axes):\n",
    "    axes[-1].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. X√ÇY D·ª∞NG V√Ä SO S√ÅNH C√ÅC M√î H√åNH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ƒê·ªãnh nghƒ©a c√°c m√¥ h√¨nh\n",
    "print(\"ü§ñ ƒê·ªäNH NGHƒ®A C√ÅC M√î H√åNH MACHINE LEARNING:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "cacMoHinh = {\n",
    "    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000),\n",
    "    'Random Forest': RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(random_state=42),\n",
    "    'XGBoost': XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "    'LightGBM': LGBMClassifier(random_state=42, verbose=-1),\n",
    "    'SVM': SVC(random_state=42, probability=True),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Decision Tree': DecisionTreeClassifier(random_state=42),\n",
    "    'AdaBoost': AdaBoostClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "print(f\"üìä S·ªë l∆∞·ª£ng m√¥ h√¨nh: {len(cacMoHinh)}\")\n",
    "for i, tenMoHinh in enumerate(cacMoHinh.keys(), 1):\n",
    "    print(f\"   {i:2d}. {tenMoHinh}\")\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a cross-validation\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(f\"\\nüîÑ Cross-validation: {cv.n_splits}-fold StratifiedKFold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# H√†m ƒë√°nh gi√° m√¥ h√¨nh\n",
    "def danhGiaMoHinh(moHinh, X_train, y_train, X_test, y_test, cv=cv):\n",
    "    \"\"\"ƒê√°nh gi√° to√†n di·ªán m·ªôt m√¥ h√¨nh\"\"\"\n",
    "    \n",
    "    # Cross-validation scores\n",
    "    cv_accuracy = cross_val_score(moHinh, X_train, y_train, cv=cv, scoring='accuracy')\n",
    "    cv_precision = cross_val_score(moHinh, X_train, y_train, cv=cv, scoring='precision')\n",
    "    cv_recall = cross_val_score(moHinh, X_train, y_train, cv=cv, scoring='recall')\n",
    "    cv_f1 = cross_val_score(moHinh, X_train, y_train, cv=cv, scoring='f1')\n",
    "    cv_roc_auc = cross_val_score(moHinh, X_train, y_train, cv=cv, scoring='roc_auc')\n",
    "    \n",
    "    # Fit v√† predict tr√™n test set\n",
    "    moHinh.fit(X_train, y_train)\n",
    "    y_pred = moHinh.predict(X_test)\n",
    "    y_pred_proba = moHinh.predict_proba(X_test)[:, 1] if hasattr(moHinh, 'predict_proba') else None\n",
    "    \n",
    "    # Test scores\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    test_precision = precision_score(y_test, y_pred)\n",
    "    test_recall = recall_score(y_test, y_pred)\n",
    "    test_f1 = f1_score(y_test, y_pred)\n",
    "    test_roc_auc = roc_auc_score(y_test, y_pred_proba) if y_pred_proba is not None else None\n",
    "    \n",
    "    return {\n",
    "        'cv_accuracy_mean': cv_accuracy.mean(),\n",
    "        'cv_accuracy_std': cv_accuracy.std(),\n",
    "        'cv_precision_mean': cv_precision.mean(),\n",
    "        'cv_precision_std': cv_precision.std(),\n",
    "        'cv_recall_mean': cv_recall.mean(),\n",
    "        'cv_recall_std': cv_recall.std(),\n",
    "        'cv_f1_mean': cv_f1.mean(),\n",
    "        'cv_f1_std': cv_f1.std(),\n",
    "        'cv_roc_auc_mean': cv_roc_auc.mean(),\n",
    "        'cv_roc_auc_std': cv_roc_auc.std(),\n",
    "        'test_accuracy': test_accuracy,\n",
    "        'test_precision': test_precision,\n",
    "        'test_recall': test_recall,\n",
    "        'test_f1': test_f1,\n",
    "        'test_roc_auc': test_roc_auc,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba,\n",
    "        'model': moHinh\n",
    "    }\n",
    "\n",
    "print(\"‚úÖ ƒê√£ ƒë·ªãnh nghƒ©a h√†m ƒë√°nh gi√° m√¥ h√¨nh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ƒê√°nh gi√° t·∫•t c·∫£ m√¥ h√¨nh v·ªõi d·ªØ li·ªáu SMOTE\n",
    "print(\"üöÄ B·∫ÆT ƒê·∫¶U ƒê√ÅNH GI√Å T·∫§T C·∫¢ M√î H√åNH:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# S·ª≠ d·ª•ng d·ªØ li·ªáu SMOTE (c√¢n b·∫±ng t·ªët nh·∫•t)\n",
    "X_train_smote, y_train_smote = duLieuSampled['SMOTE']\n",
    "\n",
    "ketQuaDanhGia = {}\n",
    "bangKetQua = []\n",
    "\n",
    "for tenMoHinh, moHinh in cacMoHinh.items():\n",
    "    print(f\"\\nüîÑ ƒêang ƒë√°nh gi√° {tenMoHinh}...\")\n",
    "    \n",
    "    try:\n",
    "        ketQua = danhGiaMoHinh(moHinh, X_train_smote, y_train_smote, X_test_processed, y_test)\n",
    "        ketQuaDanhGia[tenMoHinh] = ketQua\n",
    "        \n",
    "        # Th√™m v√†o b·∫£ng k·∫øt qu·∫£\n",
    "        bangKetQua.append({\n",
    "            'Model': tenMoHinh,\n",
    "            'CV_Accuracy': f\"{ketQua['cv_accuracy_mean']:.4f} ¬± {ketQua['cv_accuracy_std']:.4f}\",\n",
    "            'CV_Precision': f\"{ketQua['cv_precision_mean']:.4f} ¬± {ketQua['cv_precision_std']:.4f}\",\n",
    "            'CV_Recall': f\"{ketQua['cv_recall_mean']:.4f} ¬± {ketQua['cv_recall_std']:.4f}\",\n",
    "            'CV_F1': f\"{ketQua['cv_f1_mean']:.4f} ¬± {ketQua['cv_f1_std']:.4f}\",\n",
    "            'CV_ROC_AUC': f\"{ketQua['cv_roc_auc_mean']:.4f} ¬± {ketQua['cv_roc_auc_std']:.4f}\",\n",
    "            'Test_Accuracy': f\"{ketQua['test_accuracy']:.4f}\",\n",
    "            'Test_Precision': f\"{ketQua['test_precision']:.4f}\",\n",
    "            'Test_Recall': f\"{ketQua['test_recall']:.4f}\",\n",
    "            'Test_F1': f\"{ketQua['test_f1']:.4f}\",\n",
    "            'Test_ROC_AUC': f\"{ketQua['test_roc_auc']:.4f}\" if ketQua['test_roc_auc'] else 'N/A'\n",
    "        })\n",
    "        \n",
    "        print(f\"   ‚úÖ Ho√†n th√†nh - Test F1: {ketQua['test_f1']:.4f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå L·ªói: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "# T·∫°o DataFrame k·∫øt qu·∫£\n",
    "dfKetQua = pd.DataFrame(bangKetQua)\n",
    "print(f\"\\nüìä B·∫¢NG K·∫æT QU·∫¢ T·ªîNG H·ª¢P:\")\n",
    "print(\"=\"*100)\n",
    "print(dfKetQua.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bi·ªÉu ƒë·ªì so s√°nh hi·ªáu su·∫•t c√°c m√¥ h√¨nh\n",
    "fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "fig.suptitle('So s√°nh hi·ªáu su·∫•t c√°c m√¥ h√¨nh Machine Learning', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Chu·∫©n b·ªã d·ªØ li·ªáu cho bi·ªÉu ƒë·ªì\n",
    "tenMoHinh = list(ketQuaDanhGia.keys())\n",
    "cacMetric = ['test_accuracy', 'test_precision', 'test_recall', 'test_f1', 'test_roc_auc']\n",
    "tenMetric = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']\n",
    "\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (metric, ten) in enumerate(zip(cacMetric, tenMetric)):\n",
    "    if i < len(axes):\n",
    "        giaTriMetric = []\n",
    "        for moHinh in tenMoHinh:\n",
    "            giaTriMetric.append(ketQuaDanhGia[moHinh][metric] if ketQuaDanhGia[moHinh][metric] is not None else 0)\n",
    "        \n",
    "        # T·∫°o bi·ªÉu ƒë·ªì c·ªôt\n",
    "        bars = axes[i].bar(range(len(tenMoHinh)), giaTriMetric, \n",
    "                          color=plt.cm.Set3(np.linspace(0, 1, len(tenMoHinh))), alpha=0.8)\n",
    "        \n",
    "        axes[i].set_title(f'{ten} tr√™n Test Set', fontweight='bold')\n",
    "        axes[i].set_ylabel(ten)\n",
    "        axes[i].set_xticks(range(len(tenMoHinh)))\n",
    "        axes[i].set_xticklabels(tenMoHinh, rotation=45, ha='right')\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        axes[i].set_ylim(0, 1)\n",
    "        \n",
    "        # Th√™m nh√£n tr√™n c·ªôt\n",
    "        for bar, value in zip(bars, giaTriMetric):\n",
    "            axes[i].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01, \n",
    "                        f'{value:.3f}', ha='center', va='bottom', fontsize=8, fontweight='bold')\n",
    "        \n",
    "        # Highlight m√¥ h√¨nh t·ªët nh·∫•t\n",
    "        bestIdx = np.argmax(giaTriMetric)\n",
    "        bars[bestIdx].set_color('#FF6B6B')\n",
    "        bars[bestIdx].set_alpha(1.0)\n",
    "\n",
    "# Bi·ªÉu ƒë·ªì t·ªïng h·ª£p F1-Score\n",
    "if len(axes) > 5:\n",
    "    f1Scores = [ketQuaDanhGia[moHinh]['test_f1'] for moHinh in tenMoHinh]\n",
    "    sortedIndices = np.argsort(f1Scores)[::-1]\n",
    "    \n",
    "    bars = axes[5].barh(range(len(tenMoHinh)), \n",
    "                       [f1Scores[i] for i in sortedIndices],\n",
    "                       color=plt.cm.RdYlBu_r(np.linspace(0.2, 0.8, len(tenMoHinh))), alpha=0.8)\n",
    "    \n",
    "    axes[5].set_title('Ranking theo F1-Score', fontweight='bold')\n",
    "    axes[5].set_xlabel('F1-Score')\n",
    "    axes[5].set_yticks(range(len(tenMoHinh)))\n",
    "    axes[5].set_yticklabels([tenMoHinh[i] for i in sortedIndices])\n",
    "    axes[5].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Th√™m nh√£n\n",
    "    for bar, idx in zip(bars, sortedIndices):\n",
    "        axes[5].text(bar.get_width() + 0.005, bar.get_y() + bar.get_height()/2, \n",
    "                    f'{f1Scores[idx]:.3f}', ha='left', va='center', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. PH√ÇN T√çCH M√î H√åNH T·ªêT NH·∫§T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X√°c ƒë·ªãnh m√¥ h√¨nh t·ªët nh·∫•t\n",
    "print(\"üèÜ X√ÅC ƒê·ªäNH M√î H√åNH T·ªêT NH·∫§T:\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# S·∫Øp x·∫øp theo F1-score\n",
    "bangXepHang = []\n",
    "for tenMoHinh, ketQua in ketQuaDanhGia.items():\n",
    "    bangXepHang.append({\n",
    "        'Model': tenMoHinh,\n",
    "        'F1_Score': ketQua['test_f1'],\n",
    "        'ROC_AUC': ketQua['test_roc_auc'] if ketQua['test_roc_auc'] else 0,\n",
    "        'Precision': ketQua['test_precision'],\n",
    "        'Recall': ketQua['test_recall'],\n",
    "        'Accuracy': ketQua['test_accuracy']\n",
    "    })\n",
    "\n",
    "dfXepHang = pd.DataFrame(bangXepHang).sort_values('F1_Score', ascending=False)\n",
    "\n",
    "print(\"üìä TOP 5 M√î H√åNH T·ªêT NH·∫§T (theo F1-Score):\")\n",
    "print(dfXepHang.head().round(4).to_string(index=False))\n",
    "\n",
    "# L·∫•y m√¥ h√¨nh t·ªët nh·∫•t\n",
    "moHinhTotNhat = dfXepHang.iloc[0]['Model']\n",
    "ketQuaTotNhat = ketQuaDanhGia[moHinhTotNhat]\n",
    "modelTotNhat = ketQuaTotNhat['model']\n",
    "\n",
    "print(f\"\\nü•á M√î H√åNH T·ªêT NH·∫§T: {moHinhTotNhat}\")\n",
    "print(f\"   ‚Ä¢ F1-Score: {ketQuaTotNhat['test_f1']:.4f}\")\n",
    "print(f\"   ‚Ä¢ ROC-AUC: {ketQuaTotNhat['test_roc_auc']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Precision: {ketQuaTotNhat['test_precision']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Recall: {ketQuaTotNhat['test_recall']:.4f}\")\n",
    "print(f\"   ‚Ä¢ Accuracy: {ketQuaTotNhat['test_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix v√† Classification Report\n",
    "print(f\"\\nüìä PH√ÇN T√çCH CHI TI·∫æT M√î H√åNH {moHinhTotNhat}:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "y_pred_best = ketQuaTotNhat['y_pred']\n",
    "y_pred_proba_best = ketQuaTotNhat['y_pred_proba']\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred_best)\n",
    "print(\"üîç CONFUSION MATRIX:\")\n",
    "print(cm)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nüìã CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_test, y_pred_best, \n",
    "                          target_names=['Kh√¥ng ƒë·ªôt qu·ªµ', 'C√≥ ƒë·ªôt qu·ªµ']))\n",
    "\n",
    "# T√≠nh c√°c metrics b·ªï sung\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "sensitivity = tp / (tp + fn)  # = recall\n",
    "ppv = tp / (tp + fp)  # = precision\n",
    "npv = tn / (tn + fn)\n",
    "\n",
    "print(f\"\\nüìà METRICS B·ªî SUNG:\")\n",
    "print(f\"   ‚Ä¢ Sensitivity (Recall): {sensitivity:.4f}\")\n",
    "print(f\"   ‚Ä¢ Specificity: {specificity:.4f}\")\n",
    "print(f\"   ‚Ä¢ Positive Predictive Value (Precision): {ppv:.4f}\")\n",
    "print(f\"   ‚Ä¢ Negative Predictive Value: {npv:.4f}\")\n",
    "print(f\"   ‚Ä¢ True Positives: {tp}\")\n",
    "print(f\"   ‚Ä¢ True Negatives: {tn}\")\n",
    "print(f\"   ‚Ä¢ False Positives: {fp}\")\n",
    "print(f\"   ‚Ä¢ False Negatives: {fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V·∫Ω bi·ªÉu ƒë·ªì ph√¢n t√≠ch m√¥ h√¨nh t·ªët nh·∫•t\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle(f'Ph√¢n t√≠ch chi ti·∫øt m√¥ h√¨nh {moHinhTotNhat}', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Confusion Matrix Heatmap\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Kh√¥ng ƒë·ªôt qu·ªµ', 'C√≥ ƒë·ªôt qu·ªµ'],\n",
    "            yticklabels=['Kh√¥ng ƒë·ªôt qu·ªµ', 'C√≥ ƒë·ªôt qu·ªµ'],\n",
    "            ax=axes[0,0])\n",
    "axes[0,0].set_title('Confusion Matrix', fontweight='bold')\n",
    "axes[0,0].set_ylabel('Actual')\n",
    "axes[0,0].set_xlabel('Predicted')\n",
    "\n",
    "# 2. ROC Curve\n",
    "if y_pred_proba_best is not None:\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba_best)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred_proba_best)\n",
    "    \n",
    "    axes[0,1].plot(fpr, tpr, color='darkorange', lw=2, \n",
    "                   label=f'ROC curve (AUC = {roc_auc:.3f})')\n",
    "    axes[0,1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    axes[0,1].set_xlim([0.0, 1.0])\n",
    "    axes[0,1].set_ylim([0.0, 1.05])\n",
    "    axes[0,1].set_xlabel('False Positive Rate')\n",
    "    axes[0,1].set_ylabel('True Positive Rate')\n",
    "    axes[0,1].set_title('ROC Curve', fontweight='bold')\n",
    "    axes[0,1].legend(loc=\"lower right\")\n",
    "    axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Precision-Recall Curve\n",
    "if y_pred_proba_best is not None:\n",
    "    precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_proba_best)\n",
    "    \n",
    "    axes[1,0].plot(recall_curve, precision_curve, color='blue', lw=2)\n",
    "    axes[1,0].set_xlabel('Recall')\n",
    "    axes[1,0].set_ylabel('Precision')\n",
    "    axes[1,0].set_title('Precision-Recall Curve', fontweight='bold')\n",
    "    axes[1,0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Th√™m baseline\n",
    "    baseline = y_test.sum() / len(y_test)\n",
    "    axes[1,0].axhline(y=baseline, color='red', linestyle='--', \n",
    "                     label=f'Baseline ({baseline:.3f})')\n",
    "    axes[1,0].legend()\n",
    "\n",
    "# 4. Feature Importance (n·∫øu c√≥)\n",
    "if hasattr(modelTotNhat, 'feature_importances_'):\n",
    "    feature_importance = modelTotNhat.feature_importances_\n",
    "    \n",
    "    # L·∫•y top 10 features quan tr·ªçng nh·∫•t\n",
    "    top_indices = np.argsort(feature_importance)[-10:]\n",
    "    top_features = [tenFeaturesSauXuLy[i] if i < len(tenFeaturesSauXuLy) else f'Feature_{i}' \n",
    "                   for i in top_indices]\n",
    "    top_importance = feature_importance[top_indices]\n",
    "    \n",
    "    bars = axes[1,1].barh(range(len(top_features)), top_importance, \n",
    "                         color=plt.cm.viridis(np.linspace(0, 1, len(top_features))))\n",
    "    axes[1,1].set_yticks(range(len(top_features)))\n",
    "    axes[1,1].set_yticklabels(top_features)\n",
    "    axes[1,1].set_xlabel('Feature Importance')\n",
    "    axes[1,1].set_title('Top 10 Feature Importance', fontweight='bold')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Th√™m gi√° tr·ªã\n",
    "    for bar, value in zip(bars, top_importance):\n",
    "        axes[1,1].text(bar.get_width() + 0.001, bar.get_y() + bar.get_height()/2, \n",
    "                      f'{value:.3f}', ha='left', va='center', fontsize=8)\n",
    "else:\n",
    "    axes[1,1].text(0.5, 0.5, 'Feature Importance\\nkh√¥ng kh·∫£ d·ª•ng\\ncho m√¥ h√¨nh n√†y', \n",
    "                  ha='center', va='center', transform=axes[1,1].transAxes, fontsize=12)\n",
    "    axes[1,1].set_title('Feature Importance', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. HYPERPARAMETER TUNING CHO M√î H√åNH T·ªêT NH·∫§T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter tuning cho m√¥ h√¨nh t·ªët nh·∫•t\n",
    "print(f\"üîß HYPERPARAMETER TUNING CHO {moHinhTotNhat}:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ƒê·ªãnh nghƒ©a parameter grid cho c√°c m√¥ h√¨nh ph·ªï bi·∫øn\n",
    "paramGrids = {\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    },\n",
    "    'XGBoost': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 6, 10],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'subsample': [0.8, 0.9, 1.0]\n",
    "    },\n",
    "    'LightGBM': {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [3, 6, 10],\n",
    "        'learning_rate': [0.01, 0.1, 0.2],\n",
    "        'num_leaves': [31, 50, 100]\n",
    "    },\n",
    "    'Logistic Regression': {\n",
    "        'C': [0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    },\n",
    "    'SVM': {\n",
    "        'C': [0.1, 1, 10],\n",
    "        'kernel': ['rbf', 'linear'],\n",
    "        'gamma': ['scale', 'auto']\n",
    "    }\n",
    "}\n",
    "\n",
    "if moHinhTotNhat in paramGrids:\n",
    "    print(f\"üîç ƒêang t√¨m ki·∫øm hyperparameters t·ªëi ∆∞u cho {moHinhTotNhat}...\")\n",
    "    \n",
    "    # T·∫°o m√¥ h√¨nh m·ªõi\n",
    "    if moHinhTotNhat == 'Random Forest':\n",
    "        baseModel = RandomForestClassifier(random_state=42)\n",
    "    elif moHinhTotNhat == 'XGBoost':\n",
    "        baseModel = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "    elif moHinhTotNhat == 'LightGBM':\n",
    "        baseModel = LGBMClassifier(random_state=42, verbose=-1)\n",
    "    elif moHinhTotNhat == 'Logistic Regression':\n",
    "        baseModel = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    elif moHinhTotNhat == 'SVM':\n",
    "        baseModel = SVC(random_state=42, probability=True)\n",
    "    else:\n",
    "        baseModel = modelTotNhat\n",
    "    \n",
    "    # Grid Search v·ªõi cross-validation\n",
    "    gridSearch = GridSearchCV(\n",
    "        baseModel, \n",
    "        paramGrids[moHinhTotNhat],\n",
    "        cv=3,  # Gi·∫£m s·ªë fold ƒë·ªÉ tƒÉng t·ªëc\n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit tr√™n d·ªØ li·ªáu SMOTE\n",
    "    gridSearch.fit(X_train_smote, y_train_smote)\n",
    "    \n",
    "    # L·∫•y m√¥ h√¨nh t·ªët nh·∫•t\n",
    "    moHinhTuned = gridSearch.best_estimator_\n",
    "    \n",
    "    print(f\"\\n‚úÖ Ho√†n th√†nh hyperparameter tuning!\")\n",
    "    print(f\"üèÜ Best parameters: {gridSearch.best_params_}\")\n",
    "    print(f\"üìä Best CV F1-score: {gridSearch.best_score_:.4f}\")\n",
    "    \n",
    "    # ƒê√°nh gi√° m√¥ h√¨nh ƒë√£ tuned\n",
    "    y_pred_tuned = moHinhTuned.predict(X_test_processed)\n",
    "    y_pred_proba_tuned = moHinhTuned.predict_proba(X_test_processed)[:, 1]\n",
    "    \n",
    "    f1_tuned = f1_score(y_test, y_pred_tuned)\n",
    "    roc_auc_tuned = roc_auc_score(y_test, y_pred_proba_tuned)\n",
    "    precision_tuned = precision_score(y_test, y_pred_tuned)\n",
    "    recall_tuned = recall_score(y_test, y_pred_tuned)\n",
    "    accuracy_tuned = accuracy_score(y_test, y_pred_tuned)\n",
    "    \n",
    "    print(f\"\\nüìà HI·ªÜU SU·∫§T SAU TUNING:\")\n",
    "    print(f\"   ‚Ä¢ F1-Score: {f1_tuned:.4f} (tr∆∞·ªõc: {ketQuaTotNhat['test_f1']:.4f})\")\n",
    "    print(f\"   ‚Ä¢ ROC-AUC: {roc_auc_tuned:.4f} (tr∆∞·ªõc: {ketQuaTotNhat['test_roc_auc']:.4f})\")\n",
    "    print(f\"   ‚Ä¢ Precision: {precision_tuned:.4f} (tr∆∞·ªõc: {ketQuaTotNhat['test_precision']:.4f})\")\n",
    "    print(f\"   ‚Ä¢ Recall: {recall_tuned:.4f} (tr∆∞·ªõc: {ketQuaTotNhat['test_recall']:.4f})\")\n",
    "    print(f\"   ‚Ä¢ Accuracy: {accuracy_tuned:.4f} (tr∆∞·ªõc: {ketQuaTotNhat['test_accuracy']:.4f})\")\n",
    "    \n",
    "    # So s√°nh c·∫£i thi·ªán\n",
    "    caiThienF1 = f1_tuned - ketQuaTotNhat['test_f1']\n",
    "    caiThienROC = roc_auc_tuned - ketQuaTotNhat['test_roc_auc']\n",
    "    \n",
    "    print(f\"\\nüìä C·∫¢I THI·ªÜN:\")\n",
    "    print(f\"   ‚Ä¢ F1-Score: {'+' if caiThienF1 > 0 else ''}{caiThienF1:.4f}\")\n",
    "    print(f\"   ‚Ä¢ ROC-AUC: {'+' if caiThienROC > 0 else ''}{caiThienROC:.4f}\")\n",
    "    \n",
    "    if caiThienF1 > 0.01:\n",
    "        print(\"   ‚úÖ C√≥ c·∫£i thi·ªán ƒë√°ng k·ªÉ sau tuning!\")\n",
    "        moHinhCuoiCung = moHinhTuned\n",
    "        y_pred_final = y_pred_tuned\n",
    "        y_pred_proba_final = y_pred_proba_tuned\n",
    "    else:\n",
    "        print(\"   ‚ö†Ô∏è  C·∫£i thi·ªán kh√¥ng ƒë√°ng k·ªÉ, s·ª≠ d·ª•ng m√¥ h√¨nh g·ªëc\")\n",
    "        moHinhCuoiCung = modelTotNhat\n",
    "        y_pred_final = y_pred_best\n",
    "        y_pred_proba_final = y_pred_proba_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Ph√¢n t√≠ch chi ti·∫øt m√¥ h√¨nh cu·ªëi c√πng\n",
    "\n",
    "### 7.1 ƒê√°nh gi√° to√†n di·ªán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o b√°o c√°o chi ti·∫øt cho m√¥ h√¨nh cu·ªëi c√πng\n",
    "print(\"üéØ B√ÅO C√ÅO CHI TI·∫æT M√î H√åNH CU·ªêI C√ôNG\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"M√¥ h√¨nh ƒë∆∞·ª£c ch·ªçn: {type(moHinhCuoiCung).__name__}\")\n",
    "print(f\"Tham s·ªë: {moHinhCuoiCung.get_params()}\")\n",
    "\n",
    "# Ma tr·∫≠n nh·∫ßm l·∫´n chi ti·∫øt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "cm_final = confusion_matrix(y_test, y_pred_final)\n",
    "tn, fp, fn, tp = cm_final.ravel()\n",
    "\n",
    "print(f\"\\nüìä MA TR·∫¨N NH·∫¶M L·∫™N:\")\n",
    "print(f\"   True Negatives (TN): {tn}\")\n",
    "print(f\"   False Positives (FP): {fp}\")\n",
    "print(f\"   False Negatives (FN): {fn}\")\n",
    "print(f\"   True Positives (TP): {tp}\")\n",
    "\n",
    "# C√°c ch·ªâ s·ªë chi ti·∫øt\n",
    "sensitivity = tp / (tp + fn)  # Recall\n",
    "specificity = tn / (tn + fp)\n",
    "ppv = tp / (tp + fp)  # Precision\n",
    "npv = tn / (tn + fn)\n",
    "\n",
    "print(f\"\\nüìà C√ÅC CH·ªà S·ªê CHI TI·∫æT:\")\n",
    "print(f\"   Sensitivity (Recall): {sensitivity:.4f}\")\n",
    "print(f\"   Specificity: {specificity:.4f}\")\n",
    "print(f\"   Positive Predictive Value (PPV): {ppv:.4f}\")\n",
    "print(f\"   Negative Predictive Value (NPV): {npv:.4f}\")\n",
    "\n",
    "# Classification report\n",
    "print(f\"\\nüìã CLASSIFICATION REPORT:\")\n",
    "print(classification_report(y_test, y_pred_final, target_names=['Kh√¥ng ƒë·ªôt qu·ªµ', 'ƒê·ªôt qu·ªµ']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Visualizations cu·ªëi c√πng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T·∫°o c√°c bi·ªÉu ƒë·ªì cu·ªëi c√πng\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "fig.suptitle('Ph√¢n t√≠ch chi ti·∫øt m√¥ h√¨nh cu·ªëi c√πng', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 1. Confusion Matrix Heatmap\n",
    "sns.heatmap(cm_final, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['Kh√¥ng ƒë·ªôt qu·ªµ', 'ƒê·ªôt qu·ªµ'],\n",
    "            yticklabels=['Kh√¥ng ƒë·ªôt qu·ªµ', 'ƒê·ªôt qu·ªµ'],\n",
    "            ax=axes[0,0])\n",
    "axes[0,0].set_title('Ma tr·∫≠n nh·∫ßm l·∫´n')\n",
    "axes[0,0].set_xlabel('D·ª± ƒëo√°n')\n",
    "axes[0,0].set_ylabel('Th·ª±c t·∫ø')\n",
    "\n",
    "# 2. ROC Curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred_proba_final[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "axes[0,1].plot(fpr, tpr, color='darkorange', lw=2, \n",
    "               label=f'ROC curve (AUC = {roc_auc:.4f})')\n",
    "axes[0,1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "axes[0,1].set_xlim([0.0, 1.0])\n",
    "axes[0,1].set_ylim([0.0, 1.05])\n",
    "axes[0,1].set_xlabel('False Positive Rate')\n",
    "axes[0,1].set_ylabel('True Positive Rate')\n",
    "axes[0,1].set_title('ROC Curve')\n",
    "axes[0,1].legend(loc=\"lower right\")\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Precision-Recall Curve\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_pred_proba_final[:, 1])\n",
    "avg_precision = average_precision_score(y_test, y_pred_proba_final[:, 1])\n",
    "\n",
    "axes[1,0].plot(recall_curve, precision_curve, color='blue', lw=2,\n",
    "               label=f'PR curve (AP = {avg_precision:.4f})')\n",
    "axes[1,0].set_xlabel('Recall')\n",
    "axes[1,0].set_ylabel('Precision')\n",
    "axes[1,0].set_title('Precision-Recall Curve')\n",
    "axes[1,0].legend(loc=\"lower left\")\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Feature Importance (n·∫øu c√≥)\n",
    "if hasattr(moHinhCuoiCung, 'feature_importances_'):\n",
    "    # L·∫•y t√™n features t·ª´ preprocessor\n",
    "    feature_names = (list(numerical_features) + \n",
    "                    list(categorical_features) + \n",
    "                    list(binary_features))\n",
    "    \n",
    "    importances = moHinhCuoiCung.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1][:10]  # Top 10\n",
    "    \n",
    "    axes[1,1].bar(range(len(indices)), importances[indices])\n",
    "    axes[1,1].set_title('Top 10 Feature Importance')\n",
    "    axes[1,1].set_xticks(range(len(indices)))\n",
    "    axes[1,1].set_xticklabels([feature_names[i] for i in indices], rotation=45, ha='right')\n",
    "    axes[1,1].grid(True, alpha=0.3)\n",
    "else:\n",
    "    axes[1,1].text(0.5, 0.5, 'Feature Importance\\nkh√¥ng kh·∫£ d·ª•ng\\ncho m√¥ h√¨nh n√†y', \n",
    "                   ha='center', va='center', transform=axes[1,1].transAxes,\n",
    "                   fontsize=12)\n",
    "    axes[1,1].set_title('Feature Importance')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Ph√¢n t√≠ch SHAP (n·∫øu c√≥ th·ªÉ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Th·ª≠ ph√¢n t√≠ch SHAP n·∫øu c√≥ th·ªÉ\n",
    "try:\n",
    "    import shap\n",
    "    \n",
    "    print(\"üîç PH√ÇN T√çCH SHAP\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # T·∫°o explainer\n",
    "    if hasattr(moHinhCuoiCung, 'predict_proba'):\n",
    "        explainer = shap.Explainer(moHinhCuoiCung.predict_proba, X_test_processed[:100])\n",
    "        shap_values = explainer(X_test_processed[:100])\n",
    "        \n",
    "        # Summary plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        shap.summary_plot(shap_values[:,:,1], X_test_processed[:100], \n",
    "                         feature_names=feature_names, show=False)\n",
    "        plt.title('SHAP Summary Plot - T·∫ßm quan tr·ªçng c·ªßa c√°c ƒë·∫∑c tr∆∞ng')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"‚úÖ Ph√¢n t√≠ch SHAP ho√†n th√†nh\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è  M√¥ h√¨nh kh√¥ng h·ªó tr·ª£ predict_proba cho SHAP\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"‚ö†Ô∏è  SHAP kh√¥ng ƒë∆∞·ª£c c√†i ƒë·∫∑t. B·ªè qua ph√¢n t√≠ch SHAP.\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  L·ªói khi ch·∫°y SHAP: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. K·∫øt lu·∫≠n v√† ƒë·ªÅ xu·∫•t\n",
    "\n",
    "### 8.1 T√≥m t·∫Øt k·∫øt qu·∫£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T√≥m t·∫Øt k·∫øt qu·∫£ cu·ªëi c√πng\n",
    "print(\"üéØ T√ìM T·∫ÆT K·∫æT QU·∫¢ CU·ªêI C√ôNG\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"üìä M√¥ h√¨nh ƒë∆∞·ª£c ch·ªçn: {type(moHinhCuoiCung).__name__}\")\n",
    "print(f\"üìà F1-Score: {f1_score(y_test, y_pred_final):.4f}\")\n",
    "print(f\"üìà ROC-AUC: {roc_auc_score(y_test, y_pred_proba_final[:, 1]):.4f}\")\n",
    "print(f\"üìà Accuracy: {accuracy_score(y_test, y_pred_final):.4f}\")\n",
    "print(f\"üìà Precision: {precision_score(y_test, y_pred_final):.4f}\")\n",
    "print(f\"üìà Recall: {recall_score(y_test, y_pred_final):.4f}\")\n",
    "\n",
    "print(f\"\\nüéØ HI·ªÜU SU·∫§T TR√äN T·ª™NG NH√ìM:\")\n",
    "print(f\"   ‚Ä¢ Sensitivity (ph√°t hi·ªán ƒë·ªôt qu·ªµ): {sensitivity:.4f}\")\n",
    "print(f\"   ‚Ä¢ Specificity (lo·∫°i tr·ª´ kh√¥ng ƒë·ªôt qu·ªµ): {specificity:.4f}\")\n",
    "\n",
    "print(f\"\\nüí° ƒê√ÅNH GI√Å T·ªîNG QUAN:\")\n",
    "if f1_score(y_test, y_pred_final) > 0.7:\n",
    "    print(\"   ‚úÖ M√¥ h√¨nh c√≥ hi·ªáu su·∫•t t·ªët\")\n",
    "elif f1_score(y_test, y_pred_final) > 0.6:\n",
    "    print(\"   ‚ö†Ô∏è  M√¥ h√¨nh c√≥ hi·ªáu su·∫•t trung b√¨nh\")\n",
    "else:\n",
    "    print(\"   ‚ùå M√¥ h√¨nh c·∫ßn c·∫£i thi·ªán\")\n",
    "\n",
    "if sensitivity > 0.7:\n",
    "    print(\"   ‚úÖ Kh·∫£ nƒÉng ph√°t hi·ªán ƒë·ªôt qu·ªµ t·ªët\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  C·∫ßn c·∫£i thi·ªán kh·∫£ nƒÉng ph√°t hi·ªán ƒë·ªôt qu·ªµ\")\n",
    "\n",
    "if specificity > 0.7:\n",
    "    print(\"   ‚úÖ Kh·∫£ nƒÉng lo·∫°i tr·ª´ kh√¥ng ƒë·ªôt qu·ªµ t·ªët\")\n",
    "else:\n",
    "    print(\"   ‚ö†Ô∏è  C·∫ßn c·∫£i thi·ªán kh·∫£ nƒÉng lo·∫°i tr·ª´ kh√¥ng ƒë·ªôt qu·ªµ\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 L∆∞u m√¥ h√¨nh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# L∆∞u m√¥ h√¨nh v√† preprocessor\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "# T·∫°o th∆∞ m·ª•c models n·∫øu ch∆∞a c√≥\n",
    "models_dir = '../models'\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "\n",
    "# L∆∞u m√¥ h√¨nh cu·ªëi c√πng\n",
    "model_path = os.path.join(models_dir, 'moHinhDotQuy_final.pkl')\n",
    "joblib.dump(moHinhCuoiCung, model_path)\n",
    "\n",
    "# L∆∞u preprocessor\n",
    "preprocessor_path = os.path.join(models_dir, 'preprocessor.pkl')\n",
    "joblib.dump(preprocessor, preprocessor_path)\n",
    "\n",
    "# L∆∞u th√¥ng tin m√¥ h√¨nh\n",
    "model_info = {\n",
    "    'model_name': type(moHinhCuoiCung).__name__,\n",
    "    'f1_score': f1_score(y_test, y_pred_final),\n",
    "    'roc_auc': roc_auc_score(y_test, y_pred_proba_final[:, 1]),\n",
    "    'accuracy': accuracy_score(y_test, y_pred_final),\n",
    "    'precision': precision_score(y_test, y_pred_final),\n",
    "    'recall': recall_score(y_test, y_pred_final),\n",
    "    'sensitivity': sensitivity,\n",
    "    'specificity': specificity,\n",
    "    'feature_names': feature_names,\n",
    "    'training_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "}\n",
    "\n",
    "info_path = os.path.join(models_dir, 'model_info.pkl')\n",
    "joblib.dump(model_info, info_path)\n",
    "\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u m√¥ h√¨nh t·∫°i: {model_path}\")\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u preprocessor t·∫°i: {preprocessor_path}\")\n",
    "print(f\"‚úÖ ƒê√£ l∆∞u th√¥ng tin m√¥ h√¨nh t·∫°i: {info_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 ƒê·ªÅ xu·∫•t c·∫£i thi·ªán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üí° ƒê·ªÄ XU·∫§T C·∫¢I THI·ªÜN\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "print(\"üîç 1. Thu th·∫≠p th√™m d·ªØ li·ªáu:\")\n",
    "print(\"   ‚Ä¢ TƒÉng s·ªë l∆∞·ª£ng m·∫´u ƒë·ªôt qu·ªµ ƒë·ªÉ c√¢n b·∫±ng dataset\")\n",
    "print(\"   ‚Ä¢ Thu th·∫≠p th√™m c√°c ƒë·∫∑c tr∆∞ng y t·∫ø quan tr·ªçng\")\n",
    "print(\"   ‚Ä¢ D·ªØ li·ªáu theo d√µi d√†i h·∫°n\")\n",
    "\n",
    "print(\"\\nüõ†Ô∏è  2. K·ªπ thu·∫≠t c·∫£i thi·ªán m√¥ h√¨nh:\")\n",
    "print(\"   ‚Ä¢ Th·ª≠ c√°c thu·∫≠t to√°n ensemble kh√°c (Voting, Stacking)\")\n",
    "print(\"   ‚Ä¢ Feature engineering n√¢ng cao\")\n",
    "print(\"   ‚Ä¢ Hyperparameter tuning s√¢u h∆°n v·ªõi Bayesian Optimization\")\n",
    "\n",
    "print(\"\\nüìä 3. ƒê√°nh gi√° v√† validation:\")\n",
    "print(\"   ‚Ä¢ Cross-validation v·ªõi nhi·ªÅu fold h∆°n\")\n",
    "print(\"   ‚Ä¢ Validation tr√™n dataset ƒë·ªôc l·∫≠p\")\n",
    "print(\"   ‚Ä¢ Ph√¢n t√≠ch bias v√† fairness\")\n",
    "\n",
    "print(\"\\nüè• 4. ·ª®ng d·ª•ng th·ª±c t·∫ø:\")\n",
    "print(\"   ‚Ä¢ T√≠ch h·ª£p v√†o h·ªá th·ªëng y t·∫ø\")\n",
    "print(\"   ‚Ä¢ T·∫°o dashboard theo d√µi real-time\")\n",
    "print(\"   ‚Ä¢ ƒê√†o t·∫°o nh√¢n vi√™n y t·∫ø s·ª≠ d·ª•ng\")\n",
    "\n",
    "print(\"\\n‚úÖ HO√ÄN TH√ÄNH NOTEBOOK 03: X√ÇY D·ª∞NG V√Ä ƒê√ÅNH GI√Å M√î H√åNH MACHINE LEARNING\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}